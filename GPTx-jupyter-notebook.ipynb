{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e08a58-5f4a-406b-b161-012022f50f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 82/82 [01:50<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# import config and model class\n",
    "from configuration_gptx import GPTxConfig\n",
    "from modeling_gptx import GPTxForCausalLM\n",
    "import torch \n",
    "from transformers import AutoConfig, AutoModel, AutoModelForCausalLM\n",
    "#register GPTxConfig as 'GPTx'\n",
    "AutoConfig.register(\"GPTx\", GPTxConfig)\n",
    "AutoModel.register(GPTxConfig, GPTxForCausalLM)\n",
    "AutoModelForCausalLM.register(GPTxConfig, GPTxForCausalLM)\n",
    "model = AutoModelForCausalLM.from_pretrained('/cpfs01/shared/public/home/liushan/GPTx-66B/dump/global_step111600/',device_map=\"auto\",torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "707ccb9a-8119-4459-96c6-ee12433e5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('/cpfs01/shared/public/home/liushan/GPTx-66B/dump/global_step111600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab2b971-3eda-4894-9eeb-f1a9445c49fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>', '<|endoftext|>', '<unk>', '<pad>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651ab477-2b84-49df-b009-7bc7c7b5d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b17118-3979-4724-815f-87d6013bca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the inference configuration\n",
    "generation_config = GenerationConfig(\n",
    "                early_stopping=True,\n",
    "                pad_token_id=3,     # \"padding token\" index\n",
    "                max_new_tokens = 3, # max generation token length\n",
    "                eos_token_id=1,     # \"end of sequence token\" index\n",
    "                length_penalty=1.0, \n",
    "                top_p=1,            # topp=1 and top_k means use greedy-until\n",
    "                top_k=0,            # top_k=0, means use arg-max\n",
    "                do_sample=False     \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704142a3-0d4a-4ee9-9ce0-af548b3c7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3='问题:如果一个笼子里有一些鸡和兔子，其中有10个头，18条腿，请问有几只鸡，几只兔子？回答:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0148bc-5175-4f8d-a4c2-500cdeb64b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tokenization\n",
    "pt_batch_3 = tokenizer(\n",
    "                    [q3],\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\",\n",
    "                ).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b5ca55-d077-4ac6-b7b2-58c27468f8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2542,    29,  3092,  1469, 22082, 27026, 20736,  7157,   608, 59574,\n",
       "           291, 45471,    20,    19,   670,  1902,   291,    20,    27,  2267,\n",
       "         12405,   291, 29634, 50613,  1701,  7157,   291,  2533,  1701, 59574,\n",
       "          1387, 14347,    29]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434c46aa-775b-4878-a78a-23904f1bcab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_batch_3 = {'input_ids':pt_batch_3['input_ids'], 'attention_mask':pt_batch_3['attention_mask']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc5492e-1476-427d-a78b-9a6c7f5a7ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "outputs_3 = model.generate(**pt_batch_3,  max_new_tokens=100, generation_config=generation_config,\n",
    "                         output_scores=True,\n",
    "                         return_dict_in_generate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a0b1c5f-5d23-4c60-9078-789c40679e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "080ff7e2-b142-433c-9513-f6fc6e497d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2542,    29,  3092,  1469, 22082, 27026, 20736,  7157,   608, 59574,\n",
       "           291, 45471,    20,    19,   670,  1902,   291,    20,    27,  2267,\n",
       "         12405,   291, 29634, 50613,  1701,  7157,   291,  2533,  1701, 59574,\n",
       "          1387, 14347,    29, 30717, 43628,   291,   483,    20,    19,  1701,\n",
       "          7157,   291,    21,  1701, 59574,   334,  3404,  7157,   483,    20,\n",
       "            19,   670,  1902,   291, 59574,   483,    21,   670,  1902,   291,\n",
       "          3891,   483,    20,    19,  1701,  7157,   291,    21,  1701, 59574,\n",
       "           334,   189,  2542,    29,  3092,  1469, 22082, 27026, 20736,  7157,\n",
       "           608, 59574,   291, 45471,    20,    19,   670,  1902,   291,    20,\n",
       "            27,  2267, 12405,   291, 29634, 50613,  1701,  7157,   291,  2533,\n",
       "          1701, 59574,  1387, 14347,    29, 30717, 43628,   291,   483,    20,\n",
       "            19,  1701,  7157,   291,    21,  1701, 59574,   334,  3404,  7157,\n",
       "           483,    20,    19,   670,  1902,   291, 59574,   483,    21,   670,\n",
       "          1902,   291,  3891]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_indices : use outputs_3[0] or outputs_3.sequences\n",
    "outputs_3.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b336e605-53b2-4f0a-a15c-546496a236ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding of output:\n",
    "orig_outputs_3 = tokenizer.batch_decode(outputs_3.sequences, skip_special_tokens=False, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "129b2338-7f90-4aa3-9b53-ee879b41622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['问题:如果一个笼子里有一些鸡和兔子，其中有10个头，18条腿，请问有几只鸡，几只兔子？回答:这个问题很简单，有10只鸡，2只兔子。因为鸡有10个头，兔子有2个头，所以有10只鸡，2只兔子。\\n问题:如果一个笼子里有一些鸡和兔子，其中有10个头，18条腿，请问有几只鸡，几只兔子？回答:这个问题很简单，有10只鸡，2只兔子。因为鸡有10个头，兔子有2个头，所以']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_outputs_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4562cb-3e55-42a9-b21c-523ae94e740c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HAR",
   "language": "python",
   "name": "har"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
